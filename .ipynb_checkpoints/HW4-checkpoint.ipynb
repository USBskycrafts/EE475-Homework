{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e87d8573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import autograd-wrapped numpy\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from autograd import hessian\n",
    "\n",
    "# datapath to data\n",
    "datapath = './superlearn_datasets/'\n",
    "\n",
    "def model(x, w):\n",
    "    a = w[0] + np.dot(x.T, w[1:])\n",
    "    return a.T\n",
    "\n",
    "\n",
    "def newtons_method(g, max_its, w):\n",
    "    gradient = grad(g)\n",
    "    hess = hessian(g)\n",
    "    epsilon = 1e-7\n",
    "    \n",
    "    weight_his = [w]\n",
    "    cost_his = [g(w)]\n",
    "    for k in range(max_its):\n",
    "        \n",
    "        grad_eval = gradient(w)\n",
    "        hess_eval = hess(w)\n",
    "        \n",
    "        hess_eval.shape = (int(np.size(hess_eval)**0.5),\n",
    "                           int(np.size(hess_eval)**0.5))\n",
    "        A = hess_eval + epsilon*np.eye(w.size)\n",
    "        b = grad_eval\n",
    "        w = np.linalg.solve(A, np.dot(A,w)-b)\n",
    "        weight_his.append(w)\n",
    "        cost_his.append(g(w))\n",
    "    return weight_his, cost_his\n",
    "\n",
    "def gradient_descent(g, max_its, w):\n",
    "    gradient = grad(g)\n",
    "    weight_his = [w]\n",
    "    cost_his = [g(w)]\n",
    "    for k in range(max_its):\n",
    "        grad_eval = gradient(w)\n",
    "    \n",
    "        w = w - grad_eval\n",
    "        weight_his.append(w)\n",
    "        cost_his.append(g(w))\n",
    "    return weight_his, cost_his"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1695f25e",
   "metadata": {},
   "source": [
    "# 6.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89210503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.63232808]\n",
      " [ 4.55140798]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "csvname = datapath + '2d_classification_data_v1.csv'\n",
    "data = np.loadtxt(csvname,delimiter=',')\n",
    "x = data[:-1,:]\n",
    "y = data[-1:,:]\n",
    "\n",
    "w = np.ones((2, 1))\n",
    "l = 1e-3\n",
    "k = int(1e3)\n",
    "\n",
    "\n",
    "def softmax(w):\n",
    "    cost = np.sum(np.log(1+np.exp(-y*model(x,w))))\n",
    "    return cost/float(np.size(y))\n",
    "\n",
    "\n",
    "def regular(w):\n",
    "    return softmax(w) + l*np.dot(w.T, w)\n",
    "\n",
    "weight_his, cost_his = newtons_method(regular, k, w)\n",
    "mis_classified = np.sum(np.apply_along_axis(lambda x : 1 if x < 0 else 0, 0, (y*model(x, weight_his[-1]).squeeze())))\n",
    "print(mis_classified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244ea2b9",
   "metadata": {},
   "source": [
    "# 6.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d0c20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 21\n"
     ]
    }
   ],
   "source": [
    "csvname = datapath + 'breast_cancer_data.csv'\n",
    "data = np.loadtxt(csvname,delimiter = ',')\n",
    "\n",
    "# get input and output of dataset\n",
    "x = data[:-1,:]\n",
    "y = data[-1:,:]\n",
    "\n",
    "def perceptron(w):\n",
    "    cost = np.sum(-y*model(x, w) * (-y*model(x, w) > 0))\n",
    "    return cost/float(np.size(y))\n",
    "\n",
    "\n",
    "N = 9\n",
    "m1 ,m2 = 100, 100\n",
    "for _ in range(100):\n",
    "    w = np.random.rand(N,1)\n",
    "    weight_his, cost_his = gradient_descent(softmax, k, w)\n",
    "    mis_classified = np.sum(np.apply_along_axis(lambda x : 1 if x < 0 else 0, 0, (y*model(x, weight_his[-1]).squeeze())))\n",
    "    m1 = min(m1, mis_classified)\n",
    "\n",
    "\n",
    "\n",
    "    w = np.random.rand(N,1)\n",
    "    weight_his, cost_his = gradient_descent(perceptron, k, w)\n",
    "    mis_classified = np.sum(np.apply_along_axis(lambda x : 1 if x < 0 else 0, 0, (y*model(x, weight_his[-1]).squeeze())))\n",
    "    m2 = min(m2, mis_classified)\n",
    "print(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cbb417",
   "metadata": {},
   "source": [
    "We can find that they are almost the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9fca5c",
   "metadata": {},
   "source": [
    "# 6.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3779d77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144 156]\n",
      " [ 77 623]]\n",
      "0.767\n"
     ]
    }
   ],
   "source": [
    "# load in dataset\n",
    "csvname = datapath + 'credit_dataset.csv'\n",
    "data = np.loadtxt(csvname,delimiter = ',')\n",
    "x = data[:-1,:]\n",
    "y = data[-1:,:] \n",
    "\n",
    "def norm(x):\n",
    "    mu = np.sum(np.array(x), 1) / float(x.shape[1])\n",
    "    tmp = np.apply_along_axis(lambda x : x - mu, 0, x)\n",
    "    sigma = np.sqrt(np.sum(np.apply_along_axis(lambda x : x - mu, 0, x)**2, 1) / float(x.shape[1]))\n",
    "    x = np.apply_along_axis(lambda x : (x - mu) / sigma, 0, x)\n",
    "    return x\n",
    "\n",
    "x = norm(x)\n",
    "N = 21\n",
    "w = np.random.rand(N, 1)\n",
    "\n",
    "weight_his, cost_his = gradient_descent(softmax, k, w)\n",
    "A, B, C, D = 0, 0, 0, 0\n",
    "for t, p in zip(y.squeeze(), model(x, weight_his[-1]).squeeze()):\n",
    "    if (p < 0 and t < 0):\n",
    "        A += 1\n",
    "    elif (p > 0 and t < 0):\n",
    "        B += 1\n",
    "    elif (p < 0 and t > 0):\n",
    "        C += 1\n",
    "    else:\n",
    "        D += 1\n",
    "print(np.array([[A, B], [C, D]]))\n",
    "print(float(A + D) / float(C + B + D + A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad95ee7",
   "metadata": {},
   "source": [
    "# 6.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "512285af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 55)\n",
      "[[-17.68038506]\n",
      " [  9.68399168]\n",
      " [ 23.99158387]]\n",
      "[[46  4]\n",
      " [ 0  5]]\n",
      "0.9272727272727272\n"
     ]
    }
   ],
   "source": [
    "# data input\n",
    "csvname = datapath + '3d_classification_data_v2_mbalanced.csv'\n",
    "data1 = np.loadtxt(csvname,delimiter = ',')\n",
    "\n",
    "# get input and output of dataset\n",
    "x = data1[:-1,:]\n",
    "y = data1[-1:,:] \n",
    "beta = 10\n",
    "w = np.random.rand(3,1)\n",
    "\n",
    "def weighted_softmax(w):\n",
    "    ind = np.argwhere(y > 0)[:,1]\n",
    "    cost = np.sum(beta*np.log(1+np.exp(-y*model(x,w)))[:, ind])\n",
    "    ind = np.argwhere(y < 0)[:,1]\n",
    "    cost += np.sum(np.log(1+np.exp(-y*model(x,w)))[:, ind])\n",
    "    return cost/float(np.size(y))\n",
    "    \n",
    "k = 5\n",
    "weight_his, cost_his = newtons_method(weighted_softmax, k, w)\n",
    "print(weight_his[-1])\n",
    "A, B, C, D = 0, 0, 0, 0\n",
    "for t, p in zip(y.squeeze(), model(x, weight_his[-1]).squeeze()):\n",
    "    if (p < 0 and t < 0):\n",
    "        A += 1\n",
    "    elif (p > 0 and t < 0):\n",
    "        B += 1\n",
    "    elif (p < 0 and t > 0):\n",
    "        C += 1\n",
    "    else:\n",
    "        D += 1\n",
    "print(np.array([[A, B], [C, D]]))\n",
    "print(float(A + D) / float(C + B + D + A))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
